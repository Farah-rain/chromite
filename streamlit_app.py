import streamlit as st
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
import os
import joblib
import requests
import base64
from sklearn.preprocessing import LabelEncoder
from io import BytesIO

st.set_page_config(page_title="é“¬é“çŸ¿åœ°å¤–æ¥æºåˆ¤åˆ«ç³»ç»Ÿ", layout="wide")
st.title("âœ¨ é“¬é“çŸ¿ åœ°å¤–æ¥æºåˆ¤åˆ«ç³»ç»Ÿ")

# â›ï¸ æ¨¡å‹å’Œç‰¹å¾åŠ è½½
@st.cache_resource
def load_model_and_metadata():
    model_lvl1 = joblib.load("model_level1.pkl")
    model_lvl2 = joblib.load("model_level2.pkl")
    model_lvl3 = joblib.load("model_level3.pkl")

    features = model_lvl1.feature_name_  # æ‰€æœ‰æ¨¡å‹å…±ç”¨ç›¸åŒç‰¹å¾åˆ—

    le1 = LabelEncoder().fit(model_lvl1.classes_)
    le2 = LabelEncoder().fit(model_lvl2.classes_)
    le3 = LabelEncoder().fit(model_lvl3.classes_)

    return model_lvl1, model_lvl2, model_lvl3, features, le1, le2, le3

model_lvl1, model_lvl2, model_lvl3, feature_list, le1, le2, le3 = load_model_and_metadata()

# ğŸ“¤ ä¸Šä¼ æ•°æ®
uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å¾…é¢„æµ‹çš„ Excel æˆ– CSV æ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰ç‰¹å¾åˆ—ï¼‰", type=["xlsx", "csv"])

# ğŸ”¬ ä¸Šä¼ åé¢„å¤„ç†æ¨¡å—ï¼šæ°§åŒ–æ€æ‹†åˆ† + è¡ç”Ÿç‰¹å¾
def preprocess_uploaded_data(df):
    # ç›¸å¯¹åˆ†å­è´¨é‡
    mol_wt = {
        "Cr2O3": 151.99,
        "Al2O3": 101.961,
        "MgO": 40.304,
        "FeO": 71.844,
        "Fe2O3": 159.688,
    }

    # æ°§åŒ–ç‰©ä¿¡æ¯ï¼ˆç”¨äºè®¡ç®—é˜³ç¦»å­ä¸æ°§æ€»æ•°ï¼‰
    oxide_info = {
        'MgO': {'mol_wt': 40.304, 'cation_num': 1, 'oxygen_num': 1},
        'Al2O3': {'mol_wt': 101.961, 'cation_num': 2, 'oxygen_num': 3},
        'TiO2': {'mol_wt': 79.866, 'cation_num': 1, 'oxygen_num': 2},
        'V2O3': {'mol_wt': 149.881, 'cation_num': 2, 'oxygen_num': 3},
        'Cr2O3': {'mol_wt': 151.99, 'cation_num': 2, 'oxygen_num': 3},
        'MnO': {'mol_wt': 70.937, 'cation_num': 1, 'oxygen_num': 1},
        'FeO': {'mol_wt': 71.844, 'cation_num': 1, 'oxygen_num': 1},
        'ZnO': {'mol_wt': 81.38, 'cation_num': 1, 'oxygen_num': 1},
        'NiO': {'mol_wt': 74.692, 'cation_num': 1, 'oxygen_num': 1},
        'SiO2': {'mol_wt': 60.084, 'cation_num': 1, 'oxygen_num': 2},
    }

    # é˜³ç¦»å­å’Œæ°§æ€»æ•°
    def compute_totals(row):
        total_cation, total_oxygen = 0, 0
        for oxide, info in oxide_info.items():
            if pd.notna(row.get(oxide)):
                mol = row[oxide] / info['mol_wt']
                total_cation += mol * info['cation_num']
                total_oxygen += mol * info['oxygen_num']
        return pd.Series([total_cation, total_oxygen])

    df[['Cation_Total', 'Oxygen_Total']] = df.apply(compute_totals, axis=1)
    oxygen_expected = df['Cation_Total'] * 1.5
    oxygen_deficit = oxygen_expected - df['Oxygen_Total']
    FeO_mol = df['FeO'] / mol_wt['FeO']
    Fe3_mol = (oxygen_deficit * 2).clip(lower=0, upper=FeO_mol)
    Fe2_mol = FeO_mol - Fe3_mol
    df['FeO_recalc'] = Fe2_mol * mol_wt['FeO']
    df['Fe2O3_calc'] = Fe3_mol * mol_wt['Fe2O3'] / 2
    df['FeO_total'] = df['FeO_recalc'] + df['Fe2O3_calc'] * 0.8998  # ç­‰æ•ˆæ€»Fe

    # ==== è¡ç”Ÿç‰¹å¾è®¡ç®— ====
    Cr_mol = df['Cr2O3'] / mol_wt['Cr2O3'] * 2
    Al_mol = df['Al2O3'] / mol_wt['Al2O3'] * 2
    Mg_mol = df['MgO'] / mol_wt['MgO']
    Fe2_mol = df['FeO_recalc'] / mol_wt['FeO']
    Fe3_mol = df['Fe2O3_calc'] / mol_wt['Fe2O3'] * 2

    df['Cr_CrplusAl'] = Cr_mol / (Cr_mol + Al_mol)
    df['Mg_MgplusFe'] = Mg_mol / (Mg_mol + Fe2_mol)
    df['FeCrAlFe'] = Fe3_mol / (Fe3_mol + Cr_mol + Al_mol)
    df['FeMgFe'] = Fe2_mol / (Fe2_mol + Mg_mol)

    return df


# ğŸ§© ä¸»é€»è¾‘ä¸­æ•´åˆä½ç½®ï¼ˆä½ å·²æœ‰çš„ uploaded_file åˆ¤æ–­é‡Œï¼‰ï¼š
if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith(".csv"):
            df_uploaded = pd.read_csv(uploaded_file)
        else:
            df_uploaded = pd.read_excel(uploaded_file)

        # ğŸ§¬ é¢„å¤„ç† FeO/Fe2O3 æ°§åŒ–æ€æ‹†åˆ†
        df_uploaded = preprocess_iron_oxidation(df_uploaded)

        # ğŸ“¤ è°ƒç”¨åŸé¢„æµ‹ç³»ç»Ÿ
        predict_all_levels(df_uploaded)

    except Exception as e:
        st.error(f"âŒ é”™è¯¯ï¼š{str(e)}")


# ğŸ” é¢„æµ‹å‡½æ•°
def predict_all_levels(df):
    df_input = df.copy()
    for col in feature_list:
        if col not in df_input.columns:
            df_input[col] = np.nan
    df_input = df_input[feature_list].astype(float)

    # ä¸€çº§åˆ†ç±»
    prob1 = model_lvl1.predict_proba(df_input)
    pred1_idx = np.argmax(prob1, axis=1)
    pred1_label = le1.inverse_transform(pred1_idx)

    # äºŒçº§åˆ†ç±»ï¼ˆä»…é™ä¸€çº§ä¸º extraterrestrialï¼‰
    mask_lvl2 = (pred1_label == "extraterrestrial")
    df_lvl2 = df_input[mask_lvl2]
    prob2 = np.full((len(df_input), len(le2.classes_)), np.nan)
    pred2_label = np.full(len(df_input), "", dtype=object)
    if len(df_lvl2) > 0:
        prob2_masked = model_lvl2.predict_proba(df_lvl2)
        idx2 = np.argmax(prob2_masked, axis=1)
        pred2_masked = le2.inverse_transform(idx2)
        prob2[mask_lvl2] = prob2_masked
        pred2_label[mask_lvl2] = pred2_masked

    # ä¸‰çº§åˆ†ç±»ï¼ˆä»…é™äºŒçº§ä¸º OC æˆ– CCï¼‰
    mask_lvl3 = (pred2_label == "OC") | (pred2_label == "CC")
    df_lvl3 = df_input[mask_lvl3]
    prob3 = np.full((len(df_input), len(le3.classes_)), np.nan)
    pred3_label = np.full(len(df_input), "", dtype=object)
    if len(df_lvl3) > 0:
        prob3_masked = model_lvl3.predict_proba(df_lvl3)
        idx3 = np.argmax(prob3_masked, axis=1)
        pred3_masked = le3.inverse_transform(idx3)
        prob3[mask_lvl3] = prob3_masked
        pred3_label[mask_lvl3] = pred3_masked

    # ğŸ“Š ç»“æœå±•ç¤º
    result = df.copy()
    result.insert(0, "Level1_é¢„æµ‹", pred1_label)
    result.insert(1, "Level2_é¢„æµ‹", pred2_label)
    result.insert(2, "Level3_é¢„æµ‹", pred3_label)

    for i, c in enumerate(le1.classes_):
        result[f"P_Level1_{c}"] = prob1[:, i]
    for i, c in enumerate(le2.classes_):
        result[f"P_Level2_{c}"] = prob2[:, i]
    for i, c in enumerate(le3.classes_):
        result[f"P_Level3_{c}"] = prob3[:, i]

    st.subheader("ğŸ§¾ é¢„æµ‹ç»“æœï¼š")
    st.dataframe(result)

    # ğŸ“ˆ å¯è§£é‡Šæ€§åˆ†æï¼ˆSHAPï¼‰
    st.subheader("ğŸ“ˆ å¯è§£é‡Šæ€§åˆ†æï¼ˆSHAPï¼‰")
    cols = st.columns(3)
    for i, (model, name, le) in enumerate(zip([model_lvl1, model_lvl2, model_lvl3], ["Level1", "Level2", "Level3"], [le1, le2, le3])):
        with cols[i]:
            st.markdown(f"#### ğŸ” {name} æ¨¡å‹ SHAP è§£é‡Š")
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(df_input)
            class_names = le.inverse_transform(np.arange(len(le.classes_)))

            fig = plt.figure(figsize=(4, 3))
            shap.summary_plot(shap_values, df_input, plot_type="bar", class_names=class_names, show=False)
            st.pyplot(fig)
            plt.clf()

    # âœ… ç¡®è®¤åŠ å…¥è®­ç»ƒæ± 
    st.subheader("ğŸ§© æ˜¯å¦å°†é¢„æµ‹æ ·æœ¬åŠ å…¥è®­ç»ƒæ± ï¼Ÿ")
    if st.checkbox("âœ… ç¡®è®¤å°†è¿™äº›æ ·æœ¬åŠ å…¥è®­ç»ƒæ± ç”¨äºå†è®­ç»ƒ"):
        df_save = df_input.copy()
        df_save["Level1"] = pred1_label
        df_save["Level2"] = pred2_label
        df_save["Level3"] = pred3_label
        df_save.to_csv("training_pool.csv", mode="a", header=not os.path.exists("training_pool.csv"), index=False, encoding="utf-8-sig")
        st.success("âœ… æ ·æœ¬å·²åŠ å…¥è®­ç»ƒæ± ï¼")

        # ğŸ“¤ è‡ªåŠ¨ä¸Šä¼ è‡³ GitHub
        try:
            GITHUB_TOKEN = st.secrets["github"]["token"]
            repo_owner = "Farah-rain"
            repo_name = "chromite"
            file_path = "training_pool.csv"
            commit_msg = "update training pool"

            with open(file_path, "rb") as f:
                content = f.read()
                content_b64 = base64.b64encode(content).decode("utf-8")

            url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{file_path}"
            headers = {
                "Authorization": f"token {GITHUB_TOKEN}",
                "Accept": "application/vnd.github+json"
            }

            r = requests.get(url, headers=headers)
            sha = r.json()["sha"] if r.status_code == 200 else None

            data = {
                "message": commit_msg,
                "content": content_b64,
                "branch": "main"
            }
            if sha:
                data["sha"] = sha

            put_resp = requests.put(url, headers=headers, json=data)
            if put_resp.status_code in [200, 201]:
                st.success("âœ… å·²åŒæ­¥ä¸Šä¼ è‡³ GitHub ä»“åº“ï¼")
            else:
                st.warning(f"âš ï¸ GitHub ä¸Šä¼ å¤±è´¥ï¼š{put_resp.json()}")
        except Exception as e:
            st.error(f"âŒ GitHub ä¸Šä¼ å¤±è´¥ï¼š{e}")

    # ğŸ“¥ æä¾›ä¸‹è½½é¢„æµ‹ç»“æœ Excelï¼ˆæŒ‰é’®åœ¨æœ€åï¼‰
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        result.to_excel(writer, index=False, sheet_name='Prediction')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½é¢„æµ‹ç»“æœ Excel",
        data=output.getvalue(),
        file_name="prediction_results.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# ğŸ”„ ä¸»é€»è¾‘
if uploaded_file is not None:
    try:
        if uploaded_file.name.endswith(".csv"):
            df_uploaded = pd.read_csv(uploaded_file)
        else:
            df_uploaded = pd.read_excel(uploaded_file)

        # ğŸŒ‹ è‡ªåŠ¨é¢„å¤„ç† + ç‰¹å¾è¡ç”Ÿ
        df_uploaded = preprocess_uploaded_data(df_uploaded)

        # ğŸ“¤ æ¨¡å‹é¢„æµ‹
        predict_all_levels(df_uploaded)

    except Exception as e:
        st.error(f"âŒ é”™è¯¯ï¼š{str(e)}")

